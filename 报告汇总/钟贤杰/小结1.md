1.深度学习储存和操作数据的主要接口是张量（n维数组）。它提供了各种功能，包括基本数学运算、广播、索引、切片、内存节省和转换其他Python对象

2.标量、向量、矩阵和张量是线代中的基本数学对象
  向量泛化自标量，矩阵泛化自向量
  标量、向量、矩阵和张量分别具有0、1、2和任意维度的轴
  一个张量可以通过sum和mean沿指定轴降低维度
  两个矩阵按元素乘法被称为他们的Hadamard积。它与矩阵乘法不同。
  在深度学习中，我们经常使用范数，如L1范数、L2范数、Frobenius范数
  我们可以对标量、向量、矩阵、张量执行各种操作

3.微分和积分是微积分的两个分支，前者可以应用于深度学习中的优化问题
  导数可以被解释为函数相对于其变量的瞬时变化率，它也是函数曲线的切线的斜率
  梯度是一个向量，其分量是多变量函数相对于其所有变量的偏导数
  链式法则使我们能够微分复合函数

4.深度学习框架可以自动计算导数：先将梯度附加到想要对其计算偏导数的变量上。然后记录目标值的计算，执行它的反向传播函数，并访问得到的梯度

5.机器学习模型中的关键要素是训练数据、损失函数、优化算法、还有模型本身
  矢量化使数学表达上更简洁，同时运行的更快
  最小化目标函数和执行极大似然估计等价
  线性回归模型也是一个简单的神经网络

6.在Pytorch中，data模块提供了数据处理工具，nn模块定义了大量的神经网络层和常见损失函数
  通过_结尾的方式将参数替换，从而初始化参数

7.softmax运算获取一个向量并将其映射为概率
  softmax回归适用于分类问题，它使用了softmax运算中输出类别的概率分布
  交叉熵是一个衡量两个概率分布指尖差异的很好的度量，它测量给定模型编码所需的比特数

8.数据迭代器是获得更高性能的关键组件。依靠实现良好的数据迭代器，利用高性能计算来避免减慢训练过程

9.借助softmax回归，我们可以训练多分类的模型
  训练softmax回归循环模型与训练线性回归模型非常相似：先读取数据，再定义模型和损失函数，然后使用优化算法训练模型。大多数常见的深度学习模型都有类似的训练过程

10.
